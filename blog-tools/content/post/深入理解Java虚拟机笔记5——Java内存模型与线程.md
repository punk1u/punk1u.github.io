---
title: "深入理解Java虚拟机笔记5——Java内存模型与线程" 
date: 2021-06-26T14:29:39+08:00
draft: false
tags: ["JVM","笔记"]
categories:
  - "JVM"
  - "笔记"
---



在许多场景下，让计算机同时去做几件事情，不仅是因为计算机的运算能力强大了，还有一个很重要的原因是计算机的运算速度与它的存储和通信子系统的速度差距太大，大量的时间都花费在磁盘I/O、网络通信或者数据库访问上。如果不希望处理器在大部分时间里都处于等待其他资源的空闲状态，就必须使用一些手段去把处理器的运算能力“压榨”出来，否则就会造成很大的性能浪费，而让计算机同时处理几项任务则是最容易想到，也被证明是非常有效的“压榨”手段。





# Java内存模型与线程



## 硬件的效率与一致性

“让计算机并发执行若干个运算任务”与“更充分地利用计算机处理器的效能”之间的因果关系，看起来理所当然，实际上它们之间的关系并没有想象中那么简单，其中一个重要的复杂性的来源是绝大多数的运算任务都不可能只靠处理器“计算”就能完成。处理器至少要与内存交互，如读取运算数据、存储运算结果等，这个I/O操作就是很难消除的（无法仅靠寄存器来完成所有运算任务）。**由于计算机的存储设备与处理器的运算速度有着几个数量级的差距，所以现代计算机系统都不得不加入一层或多层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了**。



基于高速缓存的存储交互很好地解决了处理器与内存速度之间的矛盾，但是**也为计算机系统带来更高的复杂度，它引入了一个新的问题：缓存一致性（Cache Coherence）**。在多路处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（Main Memory），这种系统称为共享内存多核系统（Shared Memory Multiprocessors System）。**当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致**。如果真的发生这种情况，那同步回到主内存时该以谁的缓存数据为准呢？**为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作**，这类协议有`MSI`、`MESI`（Illinois Protocol）、`MOSI`、`Synapse`、`Firefly`及`Dragon Protocol`等。



除了增加高速缓存之外，**为了使处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有指令重排序（Instruction Reorder）优化**。



## Java内存模型



### 主内存与工作内存

**Java内存模型的主要目的是定义程序中各种变量的访问规则，即关注在虚拟机中把变量值存储到内存和从内存中取出变量值这样的底层细节**。此处的变量（Variables）与Java编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但是**不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题**。为了获得更好的执行效能，Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器是否要进行调整代码执行顺序这类优化措施。



Java内存模型规定了**所有的变量都存储在主内存（Main Memory）中**（此处的主内存与介绍物理硬件时提到的主内存名字一样，两者也可以类比，但物理上它仅是虚拟机内存的一部分）。**每条线程还有自己的工作内存**（Working Memory，可与前面讲的处理器高速缓存类比），**线程的工作内存中保存了被该线程使用的变量的主内存副本，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的数据**。**不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成**。关系如下图所示：



![Thread-WorkMem-MainMem-Rel](https://www.punklu.tech/assets/thread-workmem-mainmem-rel.png)





### 内存间交互操作

关于主内存与工作内存之间具体的交互协议，即**一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存这一类的实现细节，Java内存模型中定义了以下8种操作来完成**。**Java虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的**：

1. lock（锁定）

   作用于**主内存**的变量，它**把一个变量标识为一条线程独占的状态**。

2. unlock（解锁）

   作用于**主内存**的变量，它**把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定**。

3. read（读取）

   作用于**主内存**的变量，它**把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用**。

4. load（载入）

   作用于**工作内存**的变量，它**把read操作从主内存中得到的变量值放入工作内存的变量副本中**。

5. use（使用）

   作用于**工作内存**的变量，它**把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作**。

6. assign（赋值）

   作用于**工作内存**的变量，它**把一个从执行引擎接收的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作**。

7. store（存储）

   作用于**工作内存**的变量，它**把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用**。

8. write（写入）

   作用于**主内存**的变量，它**把store操作从工作内存中得到的变量的值放入主内存的变量中**。



**如果要把一个变量从主内存拷贝到工作内存，那就要按顺序执行read和load操作，如果要把变量从工作内存同步回主内存，就要按顺序执行store和write操作。注意，Java内存模型只要求上述两个操作必须按顺序执行，但不要求是连续执行**。也就是说read与load之间、store与write之间是可插入其他指令的，如对主内存中的变量a、b进行访问时，一种可能出现的顺序是read a、read b、load b、load a。



除此之外，Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则：

1. 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者工作内存发起回写了但主内存不接受的情况出现。
2. 不允许一个线程丢弃它最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。
3. 不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。
4. 一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说就是对一个变量实施use、store操作之前，必须先执行assign和load操作。
5. 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。
6. 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作以初始化变量的值。
7. 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量。
8. 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）。



这8种内存访问操作以及上述规则限定，再加上稍后会介绍的专门针对volatile的一些特殊规定，就已经能准确地描述出Java程序中哪些内存访问操作在并发下才是安全的。这种定义相当严谨，但也是极为烦琐，实践起来更是无比麻烦。Java设计团队大概也意识到了这个问题，将Java内存模型的操作简化为read、write、lock和unlock四种，但这只是语言描述上的等价化简，Java内存模型的基础设计并未改变。



### 对于volatile型变量的特殊规则

关键字`volatile`可以说是Java虚拟机提供的最轻量级的同步机制，但是它并不容易被正确、完整地理解，以至于许多程序员都习惯去避免使用它，遇到需要处理多线程数据竞争问题的时候一律使用`synchronized`来进行同步。



当一个变量被定义成`volatile`之后，它将具备两项特性：第一项是**保证此变量对所有线程的可见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的**。而普通变量并不能做到这一点，普通变量的值在线程间传递时均需要通过主内存来完成。



**`volatile`变量在各个线程的工作内存中是不存在一致性问题的**（从物理存储的角度看，各个线程的工作内存中`volatile`变量也可以存在不一致的情况，但由于每次使用之前都要先刷新，执行引擎看不到不一致的情况，因此可以认为不存在一致性问题），**但是`Java`里面的运算操作符并非原子操作，这导致volatile变量的运算在并发下一样是不安全的**：



```java
/**
* volatile变量自增运算测试
*/
public class VolatileTest {

	public static volatile int race = 0;
	public static void increase() {
		race++;
	}

    private static final int THREADS_COUNT = 20;
    
    public static void main(String[] args) {
        Thread[] threads = new Thread[THREADS_COUNT];
        for (int i = 0; i < THREADS_COUNT; i++) {
            threads[i] = new Thread(new Runnable() {
                @Override
                public void run() {
                for (int i = 0; i < 10000; i++) {
                    increase();
                    }
                }
            });
            threads[i].start();
        }
        // 等待所有累加线程都结束
        while (Thread.activeCount() > 1)
            Thread.yield();
        System.out.println(race);
    }
}
```





这段代码发起了20个线程，每个线程对race变量进行10000次自增操作，如果这段代码能够正确并发的话，最后输出的结果应该是200000。但是运行完这段代码之后，并不会获得期望的结果，而且会发现每次运行程序，输出的结果都不一样，都是一个小于200000的数字。



问题就出在自增运算“`race++`”之中，用`Javap`反编译这段代码后会得到如下所示的代码，发现只有一行代码的`increase()`方法在`Class`文件中是由`4条字节码指令`构成（`return`指令不是由`race++`产生的，这条指令可以不计算），从字节码层面上已经很容易分析出并发失败的原因了：当`getstatic`指令把`race`的值取到操作栈顶时，`volatile`关键字保证了`race`的值在此时是正确的，但是在执行`iconst_1`、`iadd`这些指令的时候，其他线程可能已经把`race`的值改变了，而操作栈顶的值就变成了过期的数据，所以`putstatic`指令执行后就可能把较小的race值同步回主内存之中。



```java
public static void increase();
    Code:
        Stack=2, Locals=0, Args_size=0
        0: getstatic #13; //Field race:I
        3: iconst_1
        4: iadd
        5: putstatic #13; //Field race:I
        8: return
    LineNumberTable:
        line 14: 0
        line 15: 8	
```



**使用字节码来分析并发问题仍然是不严谨的，因为即使编译出来只有一条字节码指令，也并不意味执行这条指令就是一个原子操作。一条字节码指令在解释执行时，解释器要运行许多行代码才能实现它的语义**。但是此处字节码就已经可以很好地说明问题了。



由于`volatile`变量只能保证可见性，在不符合以下两条规则的运算场景中，仍然要通过加锁（使用`synchronized`、`java.util.concurrent`中的锁或原子类）来保证原子性：

1. 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。
2. 变量不需要与其他的状态变量共同参与不变约束。



而在像下面所示的这类场景中就很适合使用`volatile`变量来控制并发，当`shutdown()`方法被调用时，能保证所有线程中执行的`doWork()`方法都立即停下来：

```java
volatile boolean shutdownRequested;

public void shutdown() {
	shutdownRequested = true;
}

public void doWork() {
    while (!shutdownRequested) {
    	// 代码的业务逻辑
    }
}
```



**使用volatile变量的第二个语义是禁止指令重排序优化**，**普通的变量仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致**。因为在同一个线程的方法执行过程中无法感知到这点，这就是Java内存模型中描述的所谓“线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics）。



通过一个例子来看看为何指令重排序会干扰程序的并发执行：



```java
Map configOptions;
char[] configText;
// 此变量必须定义为volatile
volatile boolean initialized = false;

// 假设以下代码在线程A中执行
// 模拟读取配置信息，当读取完成后
// 将initialized设置为true,通知其他线程配置可用
configOptions = new HashMap();
configText = readConfigFile(fileName);
processConfigOptions(configText, configOptions);
initialized = true;

// 假设以下代码在线程B中执行
// 等待initialized为true，代表线程A已经把配置信息初始化完成
while (!initialized) {
	sleep();
}
// 使用线程A中初始化好的配置信息
doSomethingWithConfig();
```



其中描述的场景是开发中常见配置读取过程，只是在处理配置文件时一般不会出现并发，所以没有察觉这会有问题。试想一下，如果定义`initialized`变量时没有使用`volatile`修饰，就可能会由于指令重排序的优化，导致位于线程A中最后一条代码“`initialized=true`”被提前执行（这里虽然使用`Java`作为伪代码，但所指的重排序优化是机器级的优化操作，提前执行是指这条语句对应的汇编代码被提前执行），这样在线程B中使用配置信息的代码就可能出现错误，而`volatile`关键字则可以避免此类情况的发生。



再举一个可以实际操作运行的双锁检测例子来分析`volatile`关键字是如何禁止指令重排序优化的 :

```java
public class Singleton {
    private volatile static Singleton instance;
    
    public static Singleton getInstance() {
        if (instance == null) {
            synchronized (Singleton.class) {
                if (instance == null) {
                	instance = new Singleton();
            	}
            }
        }
        return instance;
    }

    public static void main(String[] args) {
        Singleton.getInstance();
    }
}
```



编译后，这段代码对instance变量赋值的部分：

```assembly
0x01a3de0f: mov $0x3375cdb0,%esi 			;...beb0cd75 33
											; {oop('Singleton')}
0x01a3de14: mov %eax,0x150(%esi) 			;...89865001 0000
0x01a3de1a: shr $0x9,%esi 					;...c1ee09
0x01a3de1d: movb $0x0,0x1104800(%esi) 		;...c6860048 100100
0x01a3de24: lock addl $0x0,(%esp) 			;...f0830424 00
                                            ;*putstatic instance
                                            ; - Singleton::getInstance@24
```



通过对比发现，关键变化在于有`volatile`修饰的变量，赋值后（前面`mov%eax，0x150(%esi)`这句便是赋值操作）多执行了一个“`lock addl$0x0，(%esp)`”操作，这个操作的作用相当于一个内存屏障，只有一个处理器访问内存时，并不需要内存屏障；但如果有两个或更多处理器访问同一块内存，且其中有一个在观测另一个，就需要内存屏障来保证一致性了。



这句指令中的“`addl$0x0，(%esp)`”（把ESP寄存器的值加0）显然是一个空操作，这里的关键在于`lock`前缀，**它的作用是将本处理器的缓存写入了内存，该写入动作也会引起别的处理器或者别的内核无效化（Invalidate）其缓存**，这种操作相当于对缓存中的变量做了一次前面介绍Java内存模式中所说的“`store`和`write`”操作。所以通过这样一个空操作，可**让前面`volatile`变量的修改对其他处理器立即可见**。



从硬件架构上讲，指令重排序是指处理器采用了允许将多条指令不按程序规定的顺序分开发送给各个相应的电路单元进行处理。但并不是说指令任意重排，处理器必须能正确处理指令依赖情况保障程序能得出正确的执行结果。譬如指令1把地址A中的值加10，指令2把地址A中的值乘以2，指令3把地址B中的值减去3，这时指令1和指令2是有依赖的，它们之间的顺序不能重排——(A+10)*2与A*2+10显然不相等，但指令3可以重排到指令1、2之前或者中间，只要保证处理器执行后面依赖到A、B值的操作时能获取正确的A和B值即可。所以在同一个处理器中，重排序过的代码看起来依然是有序的。因此，**`lock addl$0x0，(%esp)`指令把修改同步到内存时，意味着所有之前的操作都已经执行完成，这样便形成了“指令重排序无法越过内存屏障”的效果**。



### 原子性、可见性与有序性

Java内存模型是围绕着在并发过程中如何处理`原子性`、`可见性`和`有序性`这三个特征来建立的，逐个来看一下哪些操作实现了这三个特性：

1. 原子性（Atomicity）

   由Java内存模型来直接保证的原子性变量操作包括`read`、`load`、`assign`、`use`、`store`和`write`这六个，大致可以认为，基本数据类型的访问、读写都是具备原子性的。

   

   如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了`lock`和`unlock`操作来满足这种需求，尽管虚拟机未把`lock`和`unlock`操作直接开放给用户使用，但是却提供了更高层次的字节码指令`monitorenter`和`monitorexit`来隐式地使用这两个操作。这两个字节码指令反映到Java代码中就是同步块——`synchronized`关键字，因此在`synchronized`块之间的操作也具备原子性。

2. 可见性（Visibility）

   `可见性`就是指**当一个线程修改了共享变量的值时，其他线程能够立即得知这个修改**。上文在讲解`volatile`变量的时候已详细讨论过这一点。`Java内存模型`是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的，无论是普通变量还是`volatile`变量都是如此。**普通变量与`volatile`变量的区别是，`volatile`的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新**。因此**可以说`volatile`保证了多线程操作时变量的可见性，而普通变量则不能保证这一点**。

   

   除了`volatile`之外，`Java`还有两个关键字能实现可见性，它们是`synchronized`和`final`。**`synchronized`同步块的可见性是由“对一个变量执行`unlock`操作之前，必须先把此变量同步回主内存中（执行`store`、`write`操作）”这条规则获得的**。而`final`关键字的可见性是指：被`final`修饰的字段在构造器中一旦被初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那么在其他线程中就能看见`final`字段的值。

3. 有序性（Ordering）

   Java语言提供了`volatile`和`synchronized`两个关键字来保证线程之间操作的有序性，**`volatile`关键字本身就包含了禁止指令重排序的语义**，**而`synchronized`则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这个规则决定了持有同一个锁的两个同步块只能串行地进入**。



### 先行发生原则

如果`Java内存模型`中所有的有序性都仅靠`volatile`和`synchronized`来完成，那么有很多操作都将会变得非常啰嗦，但是编写Java并发代码的时候并没有察觉到这一点，这是因为Java语言中有一个“先行发生”（Happens-Before）的原则。**这个原则非常重要，它是判断数据是否存在竞争，线程是否安全的非常有用的手段**。**依赖这个原则，可以通过几条简单规则一揽子解决并发环境下两个操作之间是否可能存在冲突的所有问题**，而不需要陷入Java内存模型苦涩难懂的定义之中。



先行发生是Java内存模型中定义的两项操作之间的偏序关系，比如说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。



先行发生原则示例1：

```java
// 以下操作在线程A中执行
i = 1;
// 以下操作在线程B中执行
j = i;
// 以下操作在线程C中执行
i = 2;
```



假设线程A中的操作“`i=1`”先行发生于线程B的操作“`j=i`”，那就可以确定在线程B的操作执行后，变量j的值一定是等于1，得出这个结论的依据有两个：一是根据先行发生原则，“i=1”的结果可以被观察到；二是线程C还没登场，线程A操作结束之后没有其他线程会修改变量i的值。现在再来考虑线程C，我们依然保持线程A和B之间的先行发生关系，而C出现在线程A和B的操作之间，但是C与B没有先行发生关系，那j的值会是多少呢？答案是不确定！1和2都有可能，因为线程C对变量i的影响可能会被线程B观察到，也可能不会，这时候线程B就存在读取到过期数据的风险，不具备多线程安全性。



下面是Java内存模型下一些“天然的”先行发生关系，**这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来，则它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序**：

1. 程序次序规则（Program Order Rule）

   在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。

2. 管程锁定规则（Monitor Lock Rule）

   一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是“同一个锁”，而“后面”是指时间上的先后。

3. volatile变量规则（Volatile Variable Rule）

   对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后。

4. 线程启动规则（Thread Start Rule）

   Thread对象的start()方法先行发生于此线程的每一个动作。

5. 线程终止规则（Thread Termination Rule）

   线程中的所有操作都先行发生于对此线程的终止检测，可以通过`Thread::join()`方法是否结束、`Thread::isAlive()`的返回值等手段检测线程是否已经终止执行。

6. 线程中断规则（Thread Interruption Rule）

   对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过`Thread::interrupted()`方法检测到是否有中断发生。

7. 对象终结规则（Finalizer Rule）

   一个对象的初始化完成（构造函数执行结束）先行发生于它的`finalize()`方法的开始。

8. 传递性（Transitivity）

   如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。



Java语言无须任何同步手段保障就能成立的先行发生规则有且只有上面这些，可以使用这些规则去判定操作间是否具备顺序性，对于读写共享变量的操作来说，就是线程是否安全。还可以从下面这个例子中感受一下“时间上的先后顺序”与“先行发生”之间有什么不同：



先行发生原则示例2：

```java
private int value = 0;

pubilc void setValue(int value){
	this.value = value;
}

public int getValue(){
	return value;
}
```



显示的是一组再普通不过的`getter/setter`方法，假设存在线程A和B，线程A**先（时间上的先后）调用**了`setValue(1)`，然后线程B调用了同一个对象的`getValue()`，那么线程B收到的返回值是什么？



依次分析一下先行发生原则中的各项规则。由于两个方法分别由线程A和B调用，不在一个线程中，所以程序次序规则在这里不适用；由于没有同步块，自然就不会发生lock和unlock操作，所以管程锁定规则不适用；由于value变量没有被`volatile`关键字修饰，所以`volatile`变量规则不适用；后面的线程启动、终止、中断规则和对象终结规则也和这里完全没有关系。因为没有一个适用的先行发生规则，所以最后一条传递性也无从谈起，因此我们可以判定，**尽管线程A在操作时间上先于线程B，但是无法确定线程B中`getValue()`方法的返回结果，换句话说，这里面的操作不是线程安全的。**



那怎么修复这个问题呢？至少有两种比较简单的方案可以选择：要么把`getter/setter`方法都定
义为`synchronized`方法，这样就可以套用`管程锁定规则`；要么把value定义为`volatile`变量，由于setter方法对value的修改不依赖value的原值，满足volatile关键字使用场景，这样就可以套用volatile变量规则来实现先行发生关系。



通过上面的例子，可以得出结论：**一个操作“时间上的先发生”不代表这个操作会是“先行发生”**。那**如果一个操作“先行发生”，是否就能推导出这个操作必定是“时间上的先发生”呢？很遗憾，这个推论也是不成立的**。



先行发生原则示例3：

```java
// 以下操作在同一个线程中执行
int i = 1;
int j = 2;
```

两条赋值语句在同一个线程之中，根据程序次序规则，“`int i=1`的操作先行发生于“`int j=2`”，但是“`int j=2`”的代码完全可能先被处理器执行，这并不影响先行发生原则的正确性，因为我们在这条线程之中没有办法感知到这一点。



上面两个例子综合起来证明了一个结论：**时间先后顺序与先行发生原则之间基本没有因果关系**，所以衡量并发安全问题的时候不要受时间顺序的干扰，一切必须以先行发生原则为准。



## Java与线程

并发不一定要依赖多线程（如PHP中很常见的多进程并发），但是在Java里面谈论并发，基本上都与线程脱不开关系。



线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的资源分配和执行调度分开，各个线程既可以共享进程资源（内存地址、文件I/O等），又可以独立调度。目前线程是Java里面进行处理器资源调度的最基本单位，不过如果日后Loom项目能成功为Java引入纤程（Fiber）的话，可能就会改变这一点。



### Java线程调度

**线程调度是指系统为线程分配处理器使用权的过程，调度主要方式有两种，分别是`协同式（Cooperative Threads-Scheduling）线程调度`和`抢占式（Preemptive Threads-Scheduling）线程调度`**。



**如果使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另外一个线程上去**。协同式多线程的最大好处是实现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可知的，所以一般没有什么线程同步的问题。`Lua`语言中的“协同例程”就是这类实现。它的**坏处也很明显：线程执行时间不可控制，甚至如果一个线程的代码编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里**。



如果**使用抢占式调度的多线程系统，那么每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定**。譬如在`Java`中，有`Thread::yield()`方法可以主动让出执行时间，但是**如果想要主动获取执行时间，线程本身是没有什么办法的**。在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程甚至整个系统阻塞的问题。**Java使用的线程调度方式就是抢占式调度**。



**虽然说`Java`线程调度是系统自动完成的，但是仍然可以“建议”操作系统给某些线程多分配一点执行时间，另外的一些线程则可以少分配一点——这项操作是通过设置线程优先级来完成的**。`Java`语言一共设置了10个级别的线程优先级（`Thread.MIN_PRIORITY`至`Thread.MAX_PRIORITY`）。**在两个线程同时处于`Ready`状态时，优先级越高的线程越容易被系统选择执行**。但是“建议”并不一定会被听取，也就是说**并不能在程序中通过优先级来完全准确判断一组状态都为Ready的线程将会先执行哪一个**。



### 状态转换

Java语言定义了6种线程状态，在任意一个时间点中，一个线程只能有且只有其中的一种状态，并且可以通过特定的方法在不同状态之间转换。这6种状态分别是：

1. 新建（New）：

   创建后尚未启动的线程处于这种状态。

2. 运行（Runnable）：

   包括操作系统线程状态中的Running和Ready，也就是处于此状态的线程有可能正在执行，也有可能正在等待着操作系统为它分配执行时间。

3. 无限期等待（Waiting）：

   处于这种状态的线程不会被分配处理器执行时间，**它们要等待被其他线程显式唤醒**。以下方法会让线程陷入无限期的等待状态：

   - 没有设置`Timeout`参数的`Object::wait()`方法；
   - 没有设置`Timeout`参数的`Thread::join()`方法；
   - `LockSupport::park()`方法。

4. 限期等待（Timed Waiting）：

   **处于这种状态的线程也不会被分配处理器执行时间，不过无须等待被其他线程显式唤醒，在一定时间之后它们会由系统自动唤醒**。以下方法会让线程进入限期等待状态：

   - `Thread::sleep()`方法；
   - 设置了`Timeout`参数的`Object::wait()`方法；
   - 设置了`Timeout`参数的`Thread::join()`方法；
   - `LockSupport::parkNanos()`方法；
   - `LockSupport::parkUntil()`方法。

5. 阻塞（Blocked）：

   线程被阻塞了，**“阻塞状态”与“等待状态”的区别是“阻塞状态”在等待着获取到一个排它锁，这个事件将在另外一个线程放弃这个锁的时候发生；而“等待状态”则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将进入这种状态**。

6. 结束（Terminated）：

   **已终止线程的线程状态，线程已经结束执行**。



上述6种状态在遇到特定事件发生的时候将会互相转换：

![Java线程状态转换条件](https://www.punklu.tech/assets/thread-status-change.png)



## Java与协程

在Java时代的早期，Java语言抽象出来隐藏了各种操作系统线程差异性的统一线程接口，这曾经是它区别于其他编程语言的一大优势。时至今日，这个机制依然在有效地运作着，但是在某些场景下，却也已经显现出了疲态。



### 内核线程的局限

今天对Web应用的服务要求，不论是在请求数量上还是在复杂度上，与十多年前相比已不可同日而语，这一方面是源于业务量的增长，另一方面来自于为了应对业务复杂化而不断进行的服务细分。现代B/S系统中一次对外部业务请求的响应，往往需要分布在不同机器上的大量服务共同协作来实现，这种服务细分的架构在减少单个服务复杂度、增加复用性的同时，也不可避免地增加了服务的数量，缩短了留给每个服务的响应时间。这要求每一个服务都必须在极短的时间内完成计算，这样组合多个服务的总耗时才不会太长；也要求每一个服务提供者都要能同时处理数量更庞大的请求，这样才不会出现请求由于某个服务被阻塞而出现等待。



Java目前的并发编程机制就与上述架构趋势产生了一些矛盾，**`1：1`的内核线程模型是如今Java虚拟机线程实现的主流选择，但是这种映射到操作系统上的线程天然的缺陷是切换、调度成本高昂，系统能容纳的线程数量也很有限**。以前处理一个请求可以允许花费很长时间在单体应用中，具有这种线程切换的成本也是无伤大雅的，但**现在在每个请求本身的执行时间变得很短、数量变得很多的前提下，用户线程切换的开销甚至可能会接近用于计算本身的开销，这就会造成严重的浪费**。



### 协程的复苏

为什么因为Java线程映射到了系统的内核线程中，所以切换调度成本会比较高昂呢？



**内核线程的调度成本主要来自于用户态与核心态之间的状态转换，而这两种状态转换的开销主要来自于响应中断、保护和恢复执行现场的成本**。



假设发生了这样一次线程切换：

```
线程A -> 系统中断 -> 线程B
```



**处理器要去执行线程A的程序代码时，并不是仅有代码程序就能跑得起来，程序是数据与代码的组合体，代码执行时还必须要有上下文数据的支撑**。而**这里说的“上下文”，以程序员的角度来看，是方法调用过程中的各种局部的变量与资源；以线程的角度来看，是方法的调用栈中存储的各类信息；而以操作系统和硬件的角度来看，则是存储在内存、缓存和寄存器中的一个个具体数值**。**物理硬件的各种存储设备和寄存器是被操作系统内所有线程共享的资源，当中断发生，从线程A切换到线程B去执行之前，操作系统首先要把线程A的上下文数据妥善保管好**，然后把寄存器、内存分页等恢复到线程B挂起时候的状态，这样线程B被重新激活后才能仿佛从来没有被挂起过。**这种保护和恢复现场的工作，免不了涉及一系列数据在各种寄存器、缓存中的来回拷贝，当然不可能是一种轻量级的操作**。



改为采用用户线程，内核线程的切换开销是来自于保护和恢复现场的成本也不能省略掉，但是，一旦把保护、恢复现场及调度的工作从操作系统交到程序员手上，那就可以打开脑洞，通过玩出很多新的花样来缩减这些开销。



有一些古老的操作系统（譬如DOS）是单人单工作业形式的，天生就不支持多线程，自然也不会有多个调用栈这样的基础设施。而早在那样的蛮荒时代，就已经出现了今天被称为栈纠缠（`Stack Twine`）的、由用户自己模拟多线程、自己保护恢复现场的工作模式。其大致的原理是通过在内存里划出一片额外空间来模拟调用栈，只要其他“线程”中方法压栈、退栈时遵守规则，不破坏这片空间即可，这样多段代码执行时就会像相互缠绕着一样，非常形象。



到后来，操作系统开始提供多线程的支持，靠应用自己模拟多线程的做法自然是变少了许多，但也并没有完全消失，而是演化为用户线程继续存在。由于最初多数的用户线程是被设计成协同式调（`Cooperative Scheduling`）的，所以它有了一个别名——“协程”（Coroutine）。协程的主要优势是轻量，要比传统内核线程要轻量得多。但是需要在应用层面实现的内容（调用栈、调度器这些）也特别多。具体到Java语言，还会有一些别的限制，譬如`HotSpot`这样的虚拟机，Java调用栈跟本地调用栈是做在一起的。如果在协程中调用了本地方法，还能否正常切换协程而不影响整个线程？



